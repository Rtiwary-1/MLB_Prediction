{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering and Pre-processing\n",
    "\n",
    "There are a lot of baseball datasets out there but none satisfied what I was looking for.  To solve this problem, I used the pybaseball functions that are available on James LeDoux's Github page https://github.com/jldbc/pybaseball as well as a manually downloaded archive of betting odds leading up to each game found on www.sportsbookreviewsonline.com/scoresoddsarchives/mlb/mlboddsarchives.htm.\n",
    "The pybaseball functions gather a wealth of data from online baseball databases such as baseball-reference.com and Major League Baseball's Advanced Media API.  Unfortunately for me, it is not in the form that I wanted and thus a significant amount of data wrangling was employed. The final form of the dataset that I will create has each game as its own row with home and away team attributes such as record, recent batting stats, recent bullpen pitching stats, starting pitcher's recent performance and Vegas odds going into the game.  Each of these broad categories has many data points within it and each team has dummy variables for when they are the home and away team. Going forward, the \"recent\" qualifier will be referred to as the \"lookback period.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pybaseball import schedule_and_record\n",
    "from pybaseball import statcast\n",
    "from pybaseball import playerid_lookup\n",
    "from pybaseball import statcast_pitcher\n",
    "from pybaseball import team_batting\n",
    "from pybaseball import team_pitching\n",
    "from pybaseball import batting_stats_range\n",
    "from pybaseball import pitching_stats_range\n",
    "from pybaseball import statcast_single_game\n",
    "from pybaseball import playerid_reverse_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A: Gathering data for every pitch this season\n",
    "\n",
    "The basic function that gathers every pitch for a given date range is quite simple.  However, calling the database for a large date range almost always results in an error that does not allow the data to be gathered.  The work around for this is to break the date range into smaller chunks and retry the dates that do not initially get downloaded correctly, as shown in the second piece of code.  In order to conserve space, runtime and headache I have imported the full dataframe to use going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the basic function that, in theory, should gather all of the data we are asking\n",
    "all_play_data=statcast('2019-04-02','2019-06-23')\n",
    "\n",
    "# The workaround:\n",
    "week1=pd.DataFrame([])\n",
    "for i in range(2,10):\n",
    "    day='2019-04-0'+str(i)\n",
    "    temp=pd.DataFrame([])\n",
    "    try:\n",
    "        temp=statcast(day,day)\n",
    "    except:\n",
    "        print(day)\n",
    "    if len(temp)>0:\n",
    "        week1=week1.append(pd.DataFrame(temp),ignore_index=True)\n",
    "        \n",
    "# Here is the imported the full dataframe for use going forward\n",
    "# This file exceeded Github's upload limit and thus is not in the \n",
    "# repository. However, the above code shows how to source it.\n",
    "pickle_in=open(\"2019every_pitch_june23.pickle\",\"rb\")\n",
    "every_pitch=pickle.load(pickle_in)\n",
    "\n",
    "# This is another piece of code that will save tremendous amounts of runtime by doing it all\n",
    "# at once.  This makes a dataframe of all active players and their identification numbers\n",
    "# within different databases.\n",
    "x=list(range(100000,800000))\n",
    "all_players=playerid_reverse_lookup(x)\n",
    "all_players=pd.DataFrame(all_players)\n",
    "all_players=all_players[all_players.key_fangraphs!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B: Isolating Starting Pitchers\n",
    "This function creates a dictionary of all of the starting pitchers on a given game day.  This is done so that in later on the starting pitchers can be removed from a team's pitching stats, thus isolating the team's bullpen.  This was more complicated than it would seem because of the rise of \"bullpenning.\" \"Bullpenning\" is where a team starts the game with a relief pitcher for 1 inning so that the top of the opposing team's lineup faces the traditional starter one less time.  To work around this, I classify the starting pitcher as the pitcher who pitched the most innings for a given team in each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_starters(data,lookback_start,lookback_end):\n",
    "    dates=pd.date_range(lookback_start,lookback_end)\n",
    "    all_starters={}\n",
    "    for day in dates:\n",
    "        day_starters=[]\n",
    "        day_data=data[data.game_date==day]\n",
    "        today_games=day_data.game_pk.unique()\n",
    "        for game in today_games:\n",
    "            game_stats=day_data[day_data.game_pk==game]\n",
    "            home_counter=0\n",
    "            away_counter=0\n",
    "            l=game_stats.pitcher.value_counts().keys()\n",
    "            for pitcher in l:\n",
    "                m=game_stats[game_stats.pitcher==pitcher]\n",
    "                m.reset_index(drop=True, inplace=True)\n",
    "                if home_counter==0 and m.inning_topbot[0]=='Bot':\n",
    "                    home_starter_id=pitcher\n",
    "                    home_counter+=1\n",
    "                elif away_counter==0 and m.inning_topbot[0]=='Top':\n",
    "                    away_starter_id=pitcher\n",
    "                    away_counter=+1\n",
    "                else: \n",
    "                    None\n",
    "            home_holder=all_players[all_players.key_mlbam==home_starter_id]\n",
    "            home_holder.reset_index(drop=True,inplace=True)\n",
    "            home_starter_name=str(home_holder.name_first[0])+' '+str(home_holder.name_last[0])\n",
    "            away_holder=all_players[all_players.key_mlbam==away_starter_id]\n",
    "            away_holder.reset_index(drop=True,inplace=True)\n",
    "            away_starter_name=str(away_holder.name_first[0])+' '+str(away_holder.name_last[0])\n",
    "            day_starters.append(home_starter_name)\n",
    "            day_starters.append(away_starter_name)\n",
    "        exit_date=day.strftime('%Y-%m-%d')\n",
    "        all_starters.update({exit_date:day_starters})\n",
    "    return all_starters\n",
    "starters_on_day=get_all_starters(every_pitch,'2019-04-02','2019-06-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C: Create functions for aggregating necessary statistics:\n",
    "##### team_abreviator:\n",
    "This function returns a team's abrieviation for calling a database with different team identifiers.\n",
    "\n",
    "##### get_all_relievers:\n",
    "This function finds all of the pitchers who have pitched during the lookback period and then removes the starting pitchers from that list, thus identifying all relief pitchers in a team's bullpen.\n",
    "\n",
    "##### recent_team_batting:\n",
    "This function gathers all batting stats from a team over the given lookback period.\n",
    "\n",
    "##### recent_bullpen:\n",
    "This column gathers all of the stats for a team's bullpen over the given lookback period. Note that all stats are per 9 innings.\n",
    "\n",
    "##### get_day_game_data:\n",
    "This is the main function that aggregates all of the data.It takes in a day and the amount of days to lookback and outputs a dataframe that contains all relevant game data in a single row for each game. There are more detailed descriptions of exactly what is going on throught the code.  The function will not include a game under a few fairly rare scenerios:\n",
    "- If there are multiple pitchers with the same name in the same game\n",
    "- If the same player's name is spelled differently in different databases\n",
    "- If the starting pitcher does not have any recent pitching stats (usually as a result of coming back from injury or getting called up from the minors)\n",
    "\n",
    "The function does return a dataframe of these \"failed games\" for further examination.\n",
    "\n",
    "##### get_game_data_range:\n",
    "This function gathers data for a range of dates and puts them together in a dataframe.  Note that like I mentioned in Part A, there are often errors when calling a large amount of data and the work around is to break the dates up into smaller chunks and combine them all at the end.  In order to save runtime,  I have imported the full data set at the end of the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_abreviator(team,league):\n",
    "    if team=='Atlanta':\n",
    "        return 'ATL'\n",
    "    elif team=='Arizona':\n",
    "        return 'ARI'\n",
    "    elif team=='Baltimore':\n",
    "        return 'BAL'\n",
    "    elif team=='Boston':\n",
    "        return 'BOS'\n",
    "    elif team=='Chicago':\n",
    "        if league=='MLB-AL':\n",
    "            return 'CWS'\n",
    "        else:\n",
    "            return 'CHC'\n",
    "    elif team=='Cincinnati':\n",
    "        return 'CIN'\n",
    "    elif team=='Cleveland':\n",
    "        return 'CLE'\n",
    "    elif team=='Colorado':\n",
    "        return 'COL'\n",
    "    elif team=='Detroit':\n",
    "        return 'DET'\n",
    "    elif team=='Houston':\n",
    "        return 'HOU'\n",
    "    elif team=='Kansas City':\n",
    "        return 'KC'\n",
    "    elif team=='Los Angeles':\n",
    "        if league=='MLB-AL':\n",
    "            return 'LAA'\n",
    "        else:\n",
    "            return 'LAD'\n",
    "    elif team=='Minnesota':\n",
    "        return 'MIN'\n",
    "    elif team=='Milwaukee':\n",
    "        return 'MIL'\n",
    "    elif team=='Miami':\n",
    "        return 'MIA'\n",
    "    elif team=='New York':\n",
    "        if league=='MLB-AL':\n",
    "            return 'NYY'\n",
    "        else:\n",
    "            return 'NYM'\n",
    "    elif team=='Oakland':\n",
    "        return 'OAK'\n",
    "    elif team=='Pittsburgh':\n",
    "        return 'PIT'\n",
    "    elif team=='Philadelphia':\n",
    "        return 'PHI'\n",
    "    elif team=='San Diego':\n",
    "        return 'SD'\n",
    "    elif team=='San Francisco':\n",
    "        return 'SF'\n",
    "    elif team=='Seattle':\n",
    "        return 'SEA'\n",
    "    elif team=='St. Louis':\n",
    "        return 'STL'\n",
    "    elif team=='Texas':\n",
    "        return 'TEX'\n",
    "    elif team=='Tampa Bay':\n",
    "        return 'TB'\n",
    "    elif team=='Toronto':\n",
    "        return 'TOR'\n",
    "    elif team=='Washington':\n",
    "        return 'WSH'\n",
    "    else:\n",
    "        print('Team not available in every pitch data')\n",
    "        return 0\n",
    "#####\n",
    "def get_all_relievers(starters_on_day,data,lookback_start,lookback_end):\n",
    "    dates=pd.date_range(lookback_start,lookback_end)\n",
    "    dates=dates.astype(str)\n",
    "    all_starters=[]\n",
    "    for day in dates:\n",
    "        for player in starters_on_day[day]:\n",
    "            all_starters.append(player)\n",
    "    f=pd.DataFrame(all_starters,columns=['starters'])\n",
    "    f=f.starters.unique()\n",
    "    g=pd.DataFrame(f,columns=['starters'])\n",
    "    h=pd.merge(data,g,how='outer',left_on='Name',right_on='starters',indicator=True)\n",
    "    relievers=h[h._merge!='both']\n",
    "    return relievers\n",
    "#####\n",
    "batting_columns=['team','league','ab','runs','hits','doub','trip','hr','rbi','bb','avg','obp','slg',\n",
    "                'est_ba_sa','est_woba_sa','sum_woba']\n",
    "def recent_team_batting(data,every_pitch,start,end,team,league):\n",
    "    data=data[data.iloc[:,4]==team]\n",
    "    data=data[data.iloc[:,3]==league]\n",
    "    ab=data.AB.sum()\n",
    "    hits=data.H.sum()\n",
    "    bb=data.BB.sum()+data.IBB.sum()+data.HBP.sum()\n",
    "    doub=data['2B'].sum()\n",
    "    trip=data['3B'].sum()\n",
    "    hr=data.HR.sum()\n",
    "    rbi=data.RBI.sum()\n",
    "    avg=round(hits/ab,3)\n",
    "    obp=round((hits+bb)/ab,3)\n",
    "    slg=round((hits+doub+(trip*2)+(hr*3))/ab,3)\n",
    "    runs=data.R.sum()\n",
    "    data2=every_pitch[every_pitch.game_date<=end]\n",
    "    data2=data2[data2.game_date>=start]\n",
    "    team_abrev=team_abreviator(team,league)\n",
    "    data3=data2[data2.home_team==team_abrev]\n",
    "    data3=data3[data3.inning_topbot=='Bot']\n",
    "    data4=data2[data2.away_team==team_abrev]\n",
    "    data4=data4[data4.inning_topbot=='Top']\n",
    "    data5=pd.concat([data3,data4])\n",
    "    data5=data5.dropna(subset=['launch_angle', 'launch_speed', 'estimated_ba_using_speedangle'])\n",
    "    est_ba_sa=data5.estimated_ba_using_speedangle.mean()\n",
    "    est_woba_sa=data5.estimated_woba_using_speedangle.mean()\n",
    "    sum_woba=data5.woba_value.sum() \n",
    "    df=pd.DataFrame([[team,league,ab,runs,hits,doub,trip,hr,rbi,bb,avg,obp,slg,\n",
    "                     est_ba_sa,est_woba_sa,sum_woba]],columns=batting_columns)\n",
    "    return df\n",
    "#####\n",
    "reliever_columns=['team_relief','league_relief','innings','hits','bb',\n",
    "                      'k','at_bats','doub','trip','hr','era','ba',\n",
    "                     'slg','obp','est_ba_sa','est_woba_sa','sum_woba']\n",
    "def recent_bullpen(data,every_pitch,team,league,lookback_start,lookback_end):\n",
    "    pen=data[data.Tm==team]\n",
    "    pen=pen[pen.Lev==league]\n",
    "    pen.IP=((pen.IP-round(pen.IP,0))*(10/3))+(round(pen.IP,0))\n",
    "    innings=pen.IP.sum()\n",
    "    hits=pen.H.sum()*9/innings\n",
    "    bb=(pen.BB.sum()+pen.HBP.sum()+pen.IBB.sum())*9/innings\n",
    "    k=pen.SO.sum()*9/innings\n",
    "    at_bats=pen.AB.sum()*9/innings\n",
    "    doub=pen['2B'].sum()*9/innings\n",
    "    trip=pen['3B'].sum()*9/innings\n",
    "    hr=pen.HR.sum()*9/innings\n",
    "    era=pen.ER.sum()/innings*9\n",
    "    ba=hits/at_bats\n",
    "    slg=round((hits+doub+(trip*2)+(hr*3))/at_bats,3)\n",
    "    obp=round((hits+bb)/(at_bats+bb),3)\n",
    "    data2=every_pitch[every_pitch.game_date<=lookback_end]\n",
    "    data2=data2[data2.game_date>=lookback_start]\n",
    "    team_abrev=team_abreviator(team,league)\n",
    "    data3=data2[data2.home_team==team_abrev]\n",
    "    data3=data3[data3.inning_topbot=='Bot']\n",
    "    data4=data2[data2.away_team==team_abrev]\n",
    "    data4=data4[data4.inning_topbot=='Top']\n",
    "    data5=pd.concat([data3,data4])\n",
    "    data5=data5.dropna(subset=['launch_angle', 'launch_speed', 'estimated_ba_using_speedangle'])\n",
    "    est_ba_sa=data5.estimated_ba_using_speedangle.mean()\n",
    "    est_woba_sa=data5.estimated_woba_using_speedangle.mean()\n",
    "    sum_woba=data5.woba_value.sum()/innings                  \n",
    "    df=pd.DataFrame([[team,league,innings,hits,bb,\n",
    "                      k,at_bats,doub,trip,hr,era,ba,\n",
    "                     slg,obp,est_ba_sa,est_woba_sa,sum_woba]],columns=reliever_columns)\n",
    "    return df\n",
    "#####\n",
    "def get_day_game_data(date,lookback_days):\n",
    "    # initiate variables\n",
    "    t1=datetime.datetime.now()\n",
    "    game_ids=[]                      \n",
    "    all_pitching_stats=[]\n",
    "    all_batting_stats=[]\n",
    "    data=pd.DataFrame([])\n",
    "    fails=pd.DataFrame([])\n",
    "    data2=pd.DataFrame([])\n",
    "    home_starter_stats=pd.DataFrame([])\n",
    "    away_starter_stats=pd.DataFrame([])\n",
    "    home_batting_stats=pd.DataFrame([],columns=batting_columns)\n",
    "    away_batting_stats=pd.DataFrame([],columns=batting_columns)\n",
    "    home_reliever_stats=pd.DataFrame([],columns=reliever_columns)\n",
    "    away_reliever_stats=pd.DataFrame([],columns=reliever_columns)\n",
    "    all_starting_pitchers=[]\n",
    "    #calculate necessary dates\n",
    "    lookback_end=str(pd.to_datetime(date)-pd.to_timedelta(1,unit='D'))[:10]\n",
    "    lookback_start=str(pd.to_datetime(date)-pd.to_timedelta(lookback_days+1,unit='D'))[:10]\n",
    "    today_games=statcast(start_dt=date,end_dt=date)\n",
    "    # Gather some of the necessary aggregate data\n",
    "    all_pitching_stats=pitching_stats_range(lookback_start, lookback_end)\n",
    "    all_pitching_stats.Name=all_pitching_stats.Name.str.lower()\n",
    "    all_reliever_stats=get_all_relievers(starters_on_day,all_pitching_stats,lookback_start,\n",
    "                                         lookback_end)\n",
    "    all_batting_stats=batting_stats_range(lookback_start, lookback_end)\n",
    "    game_ids=today_games.game_pk.unique()\n",
    "    game_ids=game_ids.astype(int)\n",
    "    # This deals with the occasional occurance of double headers\n",
    "    double_header_count={'BOS':0,'MIL':0,'PIT':0,'MIA':0,'ATL':0,'PHI':0,\n",
    "                      'CIN':0,'TOR':0,'ARI':0,'TEX':0,'OAK':0,'SF':0,\n",
    "                      'LAD':0,'SD':0,'WSN':0,'NYM':0,'COL':0,'KC':0,\n",
    "                      'CHW':0,'HOU':0,'BAL':0,'DET':0,'MIN':0,'CLE':0,\n",
    "                      'NYY':0,'CHC':0,'STL':0,'BOS':0,'TB':0,'TB':0,\n",
    "                      'LAA':0,'SEA':0}\n",
    "    # Within this for loop is all of the processes for gathering the data on each particular game\n",
    "    for game in game_ids:\n",
    "        #retrieve individual game stats\n",
    "        print(date)\n",
    "        print(game)\n",
    "        # There are some games that, for whatever reason, don't load properly.\n",
    "        # The try and except statements handle those and keep a log of the games that\n",
    "        # failed to load so that I can go back and gather that data manually        \n",
    "        try:\n",
    "            game_stats=statcast_single_game(game)\n",
    "        except:\n",
    "            print('game data pull failed')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':0,'Away':0,\n",
    "                                             'Reason':'game data pull failed'},index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        if len(game_stats)==0:\n",
    "            print('No game stats')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':0,'Away':0,\n",
    "                                             'Reason':'no game data'},index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        else:\n",
    "            None\n",
    "        home,away=game_stats.home_team[0],game_stats.away_team[0]\n",
    "        home_counter=0\n",
    "        away_counter=0\n",
    "        l=game_stats.pitcher.value_counts().keys()\n",
    "        #determine 'starter' by who threw the most pitches. Normally this would simply be the \n",
    "        #pitchers who were in the first inning but with the rise of 'bullpenning' this is a work-around\n",
    "        for pitcher in l:\n",
    "            m=game_stats[game_stats.pitcher==pitcher]\n",
    "            m.reset_index(drop=True, inplace=True)\n",
    "            if home_counter==0 and m.inning_topbot[0]=='Top':\n",
    "                home_starter_id=pitcher\n",
    "                home_counter+=1\n",
    "            elif away_counter==0 and m.inning_topbot[0]=='Bot':\n",
    "                away_starter_id=pitcher\n",
    "                away_counter=+1\n",
    "            else: \n",
    "                None\n",
    "        home_holder=all_players[all_players.key_mlbam==home_starter_id]\n",
    "        home_holder.reset_index(drop=True,inplace=True)\n",
    "        home_starter_name=str(home_holder.name_first[0])+' '+str(home_holder.name_last[0])\n",
    "        away_holder=all_players[all_players.key_mlbam==away_starter_id]\n",
    "        away_holder.reset_index(drop=True,inplace=True)\n",
    "        away_starter_name=str(away_holder.name_first[0])+' '+str(away_holder.name_last[0])\n",
    "        # This set of if statements handles cases where a starting pitcher does not have sufficient recent\n",
    "        # data to be useful in the model. Such as not having pitched in a while or the rare case where there\n",
    "        # are two pitchers with the same name.       \n",
    "        if len(all_pitching_stats[all_pitching_stats.Name.str.contains(home_holder.name_last[0],regex=False)])==0:\n",
    "            print('game#: ',game,' Date: ',date,' Home: ',home,' Away: ',away,'home pitcher with insuffucicient history')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'home pitcher with insuffucicient history'},\n",
    "                                            index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        elif len(all_pitching_stats[all_pitching_stats.Name.str.contains(home_holder.name_last[0],regex=False)])==1:\n",
    "            home_starter_stats=home_starter_stats.append(pd.DataFrame(all_pitching_stats[all_pitching_stats.Name.str.contains(home_holder.name_last[0],regex=False)]))\n",
    "        elif len(all_pitching_stats[all_pitching_stats.Name==home_starter_name])==1:\n",
    "            home_starter_stats=home_starter_stats.append(pd.DataFrame(all_pitching_stats[all_pitching_stats.Name==home_starter_name]))\n",
    "        else:\n",
    "            print('game#: ',game,' Date: ',date,' Home: ',home,' Away: ',away,'home pitcher with duplicate name?')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'home pitcher with duplicate name?'},\n",
    "                                            index=[0]),ignore_index=True)\n",
    "            None\n",
    "        if len(all_pitching_stats[all_pitching_stats.Name.str.contains(away_holder.name_last[0],regex=False)])==0:\n",
    "            print('game#: ',game,' Date: ',date,' Home: ',home,' Away: ',away,'away pitcher with insuffucicient history')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'away pitcher with insuffucicient history'},\n",
    "                                            index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        elif len(all_pitching_stats[all_pitching_stats.Name.str.contains(away_holder.name_last[0],regex=False)])==1:\n",
    "            away_starter_stats=away_starter_stats.append(pd.DataFrame(all_pitching_stats[all_pitching_stats.Name.str.contains(away_holder.name_last[0],regex=False)]))\n",
    "        elif len(all_pitching_stats[all_pitching_stats.Name==away_starter_name])==1:\n",
    "            away_starter_stats=away_starter_stats.append(pd.DataFrame(all_pitching_stats[all_pitching_stats.Name==away_starter_name]))\n",
    "        else:\n",
    "            print('game#: ',game,' Date: ',date,' Home: ',home,' Away: ',away,'away pitcher with duplicate name?')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'away pitcher with duplicate name?'},\n",
    "                                            index=[0]),ignore_index=True)\n",
    "            None\n",
    "        # In different databases, there are a couple teams with different abreviations: this handles that.\n",
    "        if home=='CWS':\n",
    "            home='CHW'\n",
    "        else:\n",
    "            None\n",
    "        if away=='CWS':\n",
    "            away='CHW'\n",
    "        else:\n",
    "            None\n",
    "        if home=='WSH':\n",
    "            home='WSN'\n",
    "        else:\n",
    "            None\n",
    "        if away=='WSH':\n",
    "            away='WSN'\n",
    "        else:\n",
    "            None\n",
    "        print(home,away)\n",
    "        # This section is a workaround resulting because one database does not account for\n",
    "        # extra inning games and leaves such games as a tie. To get around this I had to call\n",
    "        # a different database and determine the winner by looking at the change in the team's\n",
    "        # record after the game.\n",
    "        home_schedule_record=schedule_and_record(pd.to_datetime(date).year,home)\n",
    "        away_schedule_record=schedule_and_record(pd.to_datetime(date).year,away)\n",
    "        home_schedule_record.set_index('Date',inplace=True)\n",
    "        away_schedule_record.set_index('Date',inplace=True)\n",
    "        y,y2,y3=pd.to_datetime(date),pd.to_datetime(lookback_end),pd.to_datetime(lookback_start)\n",
    "        z,z2,z3=y.day,y2.day,y3.day\n",
    "        date_string,date_string2,date_string3=str(y.strftime('%A, %b '))+str(z),str(y2.strftime('%A, %b '))+str(z2),str(y3.strftime('%A, %b '))+str(z3)\n",
    "        date_string4=str(date_string)+str(' (1)')\n",
    "        date_string5=str(date_string)+str(' (2)')\n",
    "        \n",
    "        if any(item==date_string for item in home_schedule_record.index):\n",
    "            home_score=home_schedule_record.loc[date_string].R\n",
    "            away_score=home_schedule_record.loc[date_string].RA\n",
    "        else:\n",
    "            if sum([item==date_string for item in home_schedule_record.index])==0 and double_header_count[home]==0:\n",
    "                home_score=home_schedule_record.loc[date_string4].R\n",
    "                away_score=home_schedule_record.loc[date_string4].RA\n",
    "                double_header_count[home]=1\n",
    "            else:\n",
    "                home_score=home_schedule_record.loc[date_string5].R\n",
    "                away_score=home_schedule_record.loc[date_string5].RA\n",
    "                           \n",
    "        # determine winner    \n",
    "        if home_score>away_score:\n",
    "            home_win=1\n",
    "        elif home_score<away_score:\n",
    "            home_win=0\n",
    "        else:\n",
    "            home_win=-99\n",
    "        if any(item==date_string2 for item in home_schedule_record.index):\n",
    "            home_record=home_schedule_record.loc[date_string2]['W-L']\n",
    "        else:\n",
    "            for i in range(1,10):\n",
    "                y4=y2-pd.to_timedelta(i,unit='D')\n",
    "                y4z=y4.day\n",
    "                y4zdate=str(y4.strftime('%A, %b '))+str(y4z)\n",
    "                if any(item==y4zdate for item in away_schedule_record.index):\n",
    "                    home_record=away_schedule_record.loc[y4zdate]['W-L']\n",
    "                    break\n",
    "                else:\n",
    "                    None\n",
    "        if any(item==date_string3 for item in home_schedule_record.index):\n",
    "            home_record_lookback=home_schedule_record.loc[date_string3]['W-L']\n",
    "        else:\n",
    "            for i in range(1,10):\n",
    "                y4=y3-pd.to_timedelta(i,unit='D')\n",
    "                y4z=y4.day\n",
    "                y4zdate=str(y4.strftime('%A, %b '))+str(y4z)\n",
    "                if any(item==y4zdate for item in away_schedule_record.index):\n",
    "                    home_record_lookback=away_schedule_record.loc[y4zdate]['W-L']\n",
    "                    break\n",
    "                else:\n",
    "                    None\n",
    "        if any(item==date_string2 for item in away_schedule_record.index):\n",
    "            away_record=away_schedule_record.loc[date_string2]['W-L']\n",
    "        else:\n",
    "            for i in range(1,10):\n",
    "                y4=y2-pd.to_timedelta(i,unit='D')\n",
    "                y4z=y4.day\n",
    "                y4zdate=str(y4.strftime('%A, %b '))+str(y4z)\n",
    "                if any(item==y4zdate for item in away_schedule_record.index):\n",
    "                    away_record=away_schedule_record.loc[y4zdate]['W-L']\n",
    "                    break\n",
    "                else:\n",
    "                    None\n",
    "        if any(item==date_string3 for item in away_schedule_record.index):\n",
    "            away_record_lookback=away_schedule_record.loc[date_string3]['W-L']\n",
    "        else:\n",
    "            for i in range(1,10):\n",
    "                y4=y3-pd.to_timedelta(i,unit='D')\n",
    "                y4z=y4.day\n",
    "                y4zdate=str(y4.strftime('%A, %b '))+str(y4z)\n",
    "                if any(item==y4zdate for item in away_schedule_record.index):\n",
    "                    away_record_lookback=away_schedule_record.loc[y4zdate]['W-L']\n",
    "                    break\n",
    "                else:\n",
    "                    None\n",
    "        # This section determines the season win percentage for each team        \n",
    "        home_current_wins,home_current_losses=int(home_record.split('-')[0]),int(home_record.split('-')[1])\n",
    "        away_current_wins,away_current_losses=int(away_record.split('-')[0]),int(away_record.split('-')[1])\n",
    "        home_pct=home_current_wins/(home_current_wins+home_current_losses)\n",
    "        away_pct=away_current_wins/(away_current_wins+away_current_losses)        \n",
    "        # This section determines the recent win percentage for each team\n",
    "        home_lookback_wins,home_lookback_losses=int(home_record_lookback.split('-')[0]),int(home_record_lookback.split('-')[1])\n",
    "        away_lookback_wins,away_lookback_losses=int(away_record_lookback.split('-')[0]),int(away_record_lookback.split('-')[1])\n",
    "        home_recent_wins,home_recent_losses=home_current_wins-home_lookback_wins,home_current_losses-home_lookback_losses\n",
    "        away_recent_wins,away_recent_losses=away_current_wins-away_lookback_wins,away_current_losses-away_lookback_losses\n",
    "        home_streak=home_recent_wins/(home_recent_wins+home_recent_losses)\n",
    "        away_streak=away_recent_wins/(away_recent_wins+away_recent_losses)\n",
    "        # This section gathers some advanced statistics about the starting pitchers\n",
    "        home_starter_adv=statcast_pitcher(lookback_start, lookback_end,int(home_starter_id))\n",
    "        if len(home_starter_adv)==0:\n",
    "            print('No home starter advanced stats')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'No home starter advanced stats'},index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        else:\n",
    "            None\n",
    "        home_starter_launch=home_starter_adv.launch_speed.mean()\n",
    "        home_starter_adv = home_starter_adv.dropna(subset=['launch_angle', 'launch_speed', 'estimated_ba_using_speedangle'])\n",
    "        home_starter_est_ba_sa=home_starter_adv.estimated_ba_using_speedangle.mean()\n",
    "        home_starter_est_woba_sa=home_starter_adv.estimated_woba_using_speedangle.mean()\n",
    "        home_starter_sum_woba=home_starter_adv.woba_value.sum()\n",
    "        away_starter_adv=statcast_pitcher(lookback_start, lookback_end,int(away_starter_id))\n",
    "        if len(away_starter_adv)==0:\n",
    "            print('No away starter advanced stats')\n",
    "            fails=fails.append(pd.DataFrame({'game#':game,'Date':date,'Home':home,'Away':away,\n",
    "                                             'Reason':'No away starter advanced stats'},index=[0]),ignore_index=True)\n",
    "            continue\n",
    "        else:\n",
    "            None\n",
    "        away_starter_launch=away_starter_adv.launch_speed.mean()\n",
    "        away_starter_adv = away_starter_adv.dropna(subset=['launch_angle', 'launch_speed', 'estimated_ba_using_speedangle'])\n",
    "        away_starter_est_ba_sa=away_starter_adv.estimated_ba_using_speedangle.mean()\n",
    "        away_starter_est_woba_sa=away_starter_adv.estimated_woba_using_speedangle.mean()\n",
    "        away_starter_sum_woba=away_starter_adv.woba_value.sum()\n",
    "        data=data.append(pd.DataFrame({'home_win':home_win,'home_score':home_score,\n",
    "                                       'away_score':away_score,'date':date,'lookback_days':lookback_days,\n",
    "                                       'home_team':home,'away_team':away,'home_pct':home_pct,'away_pct':away_pct,\n",
    "                                       'home_streak':home_streak,'away_streak':away_streak,\n",
    "                                       'home_starter_name':home_starter_name,\n",
    "                                       'away_starter_name':away_starter_name,'home_starter_id':home_starter_id,\n",
    "                                       'away_starter_id':away_starter_id,'home_starter_launch':home_starter_launch,\n",
    "                                       'home_starter_est_ba_sa':home_starter_est_ba_sa,\n",
    "                                       'home_starter_est_woba_sa':home_starter_est_woba_sa,\n",
    "                                       'home_starter_sum_woba':home_starter_sum_woba,\n",
    "                                      'away_starter_launch':away_starter_launch,\n",
    "                                      'away_starter_est_ba_sa':away_starter_est_ba_sa,\n",
    "                                       'away_starter_est_woba_sa':away_starter_est_woba_sa,\n",
    "                                       'away_starter_sum_woba':away_starter_sum_woba},index=[0]),ignore_index=True)\n",
    "        all_starting_pitchers.append(home_starter_name)\n",
    "        all_starting_pitchers.append(away_starter_name)\n",
    "        home_starter_stats.reset_index(drop=True,inplace=True)\n",
    "        away_starter_stats.reset_index(drop=True,inplace=True)\n",
    "        # This section calls the other functions and gathers data about each team\n",
    "        home_batting=recent_team_batting(all_batting_stats,every_pitch,lookback_start, lookback_end,home_starter_stats.Tm[len(home_starter_stats)-1],home_starter_stats.Lev[len(home_starter_stats)-1])\n",
    "        home_batting_stats=home_batting_stats.append((pd.DataFrame(home_batting)))\n",
    "        away_batting=recent_team_batting(all_batting_stats,every_pitch,lookback_start, lookback_end,away_starter_stats.Tm[len(away_starter_stats)-1],away_starter_stats.Lev[len(away_starter_stats)-1])\n",
    "        away_batting_stats=away_batting_stats.append((pd.DataFrame(away_batting)))\n",
    "        home_relief=recent_bullpen(all_reliever_stats,every_pitch,home_starter_stats.Tm[len(home_starter_stats)-1],\n",
    "                                   home_starter_stats.Lev[len(home_starter_stats)-1],lookback_start,lookback_end)\n",
    "        home_reliever_stats=home_reliever_stats.append((pd.DataFrame(home_relief)))\n",
    "        away_relief=recent_bullpen(all_reliever_stats,every_pitch,away_starter_stats.Tm[len(away_starter_stats)-1],\n",
    "                                   away_starter_stats.Lev[len(away_starter_stats)-1],lookback_start,lookback_end)\n",
    "        away_reliever_stats=away_reliever_stats.append((pd.DataFrame(away_relief)))\n",
    "    # This section joins all of the data into a single dataframe and renames many of the columns for easier understanding\n",
    "    data['home_join']=data.home_starter_name.str.replace(' ','')\n",
    "    data['away_join']=data.away_starter_name.str.replace(' ','')\n",
    "    home_starter_stats.columns=['hs'+str(col) for col in home_starter_stats.columns]\n",
    "    away_starter_stats.columns=['as'+str(col) for col in away_starter_stats.columns]\n",
    "    home_batting_stats.columns=['home_bat_'+str(col) for col in home_batting_stats.columns]\n",
    "    away_batting_stats.columns=['away_bat_'+str(col) for col in away_batting_stats.columns]\n",
    "    home_reliever_stats.columns=['homepen_'+str(col) for col in home_reliever_stats.columns]\n",
    "    away_reliever_stats.columns=['awaypen_'+str(col) for col in away_reliever_stats.columns]\n",
    "    home_starter_stats['hsjoin']=home_starter_stats.hsName.str.replace(' ','')\n",
    "    away_starter_stats['asjoin']=away_starter_stats.asName.str.replace(' ','')\n",
    "    data=data.merge(home_starter_stats,left_on='home_join',right_on='hsjoin')\n",
    "    data=data.merge(away_starter_stats,left_on='away_join',right_on='asjoin')\n",
    "    data=data.merge(home_batting_stats,how='left',left_on=['hsTm','hsLev'],right_on=['home_bat_team','home_bat_league'])\n",
    "    data=data.merge(away_batting_stats,how='left',left_on=['asTm','asLev'],right_on=['away_bat_team','away_bat_league'])\n",
    "    data=data.merge(home_reliever_stats,how='left',left_on=['hsTm','hsLev'],right_on=['homepen_team_relief','homepen_league_relief'])\n",
    "    data=data.merge(away_reliever_stats,how='left',left_on=['asTm','asLev'],right_on=['awaypen_team_relief','awaypen_league_relief'])\n",
    "    data.drop(['hsTm','asTm','away_join','home_join','asName','as#days',\n",
    "                'asAge','asLev','hsName','hs#days','hsAge','hsLev','hsjoin',\n",
    "                'asjoin','homepen_team_relief','homepen_league_relief',\n",
    "               'awaypen_team_relief','awaypen_league_relief'],axis=1,inplace=True)\n",
    "    data=data.drop_duplicates()\n",
    "    return data,fails\n",
    "#####\n",
    "def get_game_data_range(start,end,lookback_days):\n",
    "    dates=pd.date_range(start,end)\n",
    "    dates=dates.astype(str)\n",
    "    data=pd.DataFrame([])\n",
    "    fails=pd.DataFrame([])\n",
    "    for day in dates:\n",
    "        day_data,day_fails=get_day_game_data(day,lookback_days)\n",
    "        data=pd.concat([data,day_data],ignore_index=True)\n",
    "        fails=pd.concat([fails,day_fails],ignore_index=True)\n",
    "    return data,fails\n",
    "pickle_in=open(\"2019_data_june23.pickle\",\"rb\")\n",
    "game_data=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part D: Adding betting odds to the dataframe:\n",
    "This process takes the odds from a manually downloaded csv file and adds them into the data frame while also adding a home team implied win probablility column.  The odds file is downloaded from www.sportsbookreviewsonline.com/scoresoddsarchives/mlb/mlboddsarchives.htm. There is a little bit of editing that needs to be done in the csv file before it is loaded into this notebook.  The only columns that should remain are:\n",
    "    Date, Team, Pitcher, Open, Close, OpenOU, and CloseOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The section below transforms the dates into the form that matches the rest of this notebook\n",
    "odds_data=pd.read_csv('mlb2019odds_june23.csv')\n",
    "odds_data['month']=round(odds_data.Date/100).astype(int)\n",
    "odds_data['day']=(odds_data.Date-odds_data.month*100).astype(int)\n",
    "odds_data['game_day']=0\n",
    "# This corrects team abreviations from the odds_data file\n",
    "for i in range(len(odds_data)):\n",
    "    if odds_data.Team[i]=='SFO':\n",
    "        odds_data.Team[i]='SF'\n",
    "    elif odds_data.Team[i]=='WAS':\n",
    "        odds_data.Team[i]='WSN'\n",
    "    elif odds_data.Team[i]=='TAM':\n",
    "        odds_data.Team[i]='TB'\n",
    "    elif odds_data.Team[i]=='CWS':\n",
    "        odds_data.Team[i]='CHW'\n",
    "    elif odds_data.Team[i]=='KAN':\n",
    "        odds_data.Team[i]='KC'\n",
    "    elif odds_data.Team[i]=='CUB':\n",
    "        odds_data.Team[i]='CHC'\n",
    "    elif odds_data.Team[i]=='SDG':\n",
    "        odds_data.Team[i]='SD'\n",
    "    else:\n",
    "        None   \n",
    "    year=2019\n",
    "    month=odds_data.month[i]\n",
    "    day=odds_data.day[i]\n",
    "    odds_data['game_day'][i]=datetime.date(2019,month,day).strftime('%Y-%m-%d')\n",
    "# This initiates the necessary variables\n",
    "game_data['home_money_open']=None\n",
    "game_data['home_money_close']=None\n",
    "game_data['home_money_change']=None\n",
    "game_data['away_money_open']=None\n",
    "game_data['away_money_close']=None\n",
    "game_data['away_money_change']=None\n",
    "game_data['home_prob_open']=None\n",
    "game_data['home_prob_close']=None\n",
    "game_data['home_prob_change']=None\n",
    "game_data['ou_open']=None\n",
    "game_data['ou_close']=None   \n",
    "# This function uses the money line odds to calculate the betting markets implied\n",
    "# probablility of the home team winning \n",
    "def home_pct_chance(home_money,away_money):\n",
    "    if home_money>0:\n",
    "        a1=100/(home_money+100)\n",
    "    else:\n",
    "        a1=-home_money/(100-home_money)\n",
    "    if away_money>0:\n",
    "        a2=100/(away_money+100)\n",
    "    else:\n",
    "        a2=-away_money/(100-away_money)\n",
    "    return(a1/(a1+a2))\n",
    "# This for loop fills in the relevant betting related columns into the data frame\n",
    "for i in range(len(game_data)):\n",
    "    try:\n",
    "        home=[]\n",
    "        away=[]\n",
    "        date=game_data.date[i]\n",
    "        home_team=game_data.home_team[i]\n",
    "        away_team=game_data.away_team[i]\n",
    "        home=odds_data.ix[(odds_data['game_day']==date) & (odds_data['Team']==home_team)]\n",
    "        away=odds_data.ix[(odds_data['game_day']==date) & (odds_data['Team']==away_team)]\n",
    "        home.reset_index(drop=True,inplace=True)\n",
    "        away.reset_index(drop=True,inplace=True)\n",
    "        game_data.home_money_close[i]=int(home.Close[0])\n",
    "        if home.Open[0]=='NL':\n",
    "            game_data.home_money_open[i]=game_data.home_money_close[i]\n",
    "            game_data.home_money_change[i]=0\n",
    "        else:\n",
    "            game_data.home_money_open[i]=int(home.Open[0])\n",
    "            game_data.home_money_change[i]=int(home.Close[0])-int(home.Open[0]) \n",
    "        game_data.away_money_close[i]=int(away.Close[0])\n",
    "        if away.Open[0]=='NL':\n",
    "            game_data.away_money_open[i]=game_data.away_money_close[i]\n",
    "            game_data.away_money_change[i]=0\n",
    "        else:\n",
    "            game_data.away_money_open[i]=int(away.Open[0])\n",
    "            game_data.away_money_change[i]=int(away.Close[0])-int(away.Open[0]) \n",
    "        game_data.home_prob_open[i]=home_pct_chance(game_data.home_money_open[i],game_data.away_money_open[i])\n",
    "        game_data.home_prob_close[i]=home_pct_chance(game_data.home_money_close[i],game_data.away_money_close[i])\n",
    "        game_data.home_prob_change[i]=game_data.home_prob_close[i]-game_data.home_prob_open[i]\n",
    "        game_data.ou_open[i]=home.OpenOU[0]\n",
    "        game_data.ou_close[i]=away.CloseOU[0]\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part E: Final data cleaning\n",
    "In this short section we add dummy variables for each team and drop the unnecessary columns.  I also move the \"home_money_close\" and \"away_money_close\" variables to the very end. This is because these are the odds that you would bet right before the game starts and having them at the end of the data frame makes retrieving those values easier later on in the modeling process.  The last thing I do is use the pickle functions to save and export this dataframe for use in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_data=game_data.fillna(0)\n",
    "game_data=game_data[game_data.home_streak<1.001]\n",
    "game_data=game_data[game_data.away_streak<1.001]\n",
    "game_data=game_data[game_data.home_streak>-.001]\n",
    "game_data=game_data[game_data.away_streak>-.001]\n",
    "df=game_data.copy()\n",
    "home_dummies=pd.get_dummies(df.home_team)\n",
    "away_dummies=pd.get_dummies(df.away_team)\n",
    "home_dummies.columns=['h_'+str(col) for col in home_dummies.columns]\n",
    "away_dummies.columns=['a_'+str(col) for col in away_dummies.columns]\n",
    "df=df.merge(home_dummies,left_index=True,right_index=True)\n",
    "df=df.merge(away_dummies,left_index=True,right_index=True)\n",
    "df.drop(['date','lookback_days','home_team','away_team','home_starter_name',\n",
    "         'away_starter_name','home_starter_id','away_starter_id','home_bat_team','home_bat_league',\n",
    "        'away_bat_team','away_bat_league'],axis=1,inplace=True)\n",
    "# This moves the final moneyline to the last columns to make it easier to examine the real world application later on\n",
    "df['home_money_close2']=df.home_money_close\n",
    "df['away_money_close2']=df.away_money_close\n",
    "df.drop(['home_money_close','away_money_close'],axis=1,inplace=True)\n",
    "df['home_money_close']=df.home_money_close2\n",
    "df['away_money_close']=df.away_money_close2\n",
    "df.drop(['home_money_close2','away_money_close2'],axis=1,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "pickle_out=open(\"cleaned_data.pickle\",\"wb\")\n",
    "pickle.dump(df,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the next section please see the notebook titled \"Data_Exploration_and_Visualization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
