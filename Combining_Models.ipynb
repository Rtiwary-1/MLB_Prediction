{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Models\n",
    "In this notebook I will take the three best models from the previous section and combine them in various ways in order to create a more powerful model for predicting MLB games.  For details on what the parameters are, please see the previous notebook.\n",
    "\n",
    "Below I have imported the necessary libraries along with the functions created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 225)\n",
    "pickle_in=open(\"cleaned_data.pickle\",\"rb\")\n",
    "df=pickle.load(pickle_in)\n",
    "# I need to drop two columns that I left in for the visualization notebook\n",
    "df.drop(['home_score','away_score'],axis=1,inplace=True)\n",
    "# This is the same function from the previous notebook and it will be used to\n",
    "# evaluate model performance\n",
    "def calc_return(X_analyse):\n",
    "    total_risk=[]\n",
    "    total_reward=[]\n",
    "    equal_bet_return=[]\n",
    "    for i in range(len(X_analyse)):\n",
    "        k=pd.DataFrame(X_analyse.iloc[i]).transpose()\n",
    "        k.reset_index(drop=True,inplace=True)\n",
    "        if int(k.preds[0])==1:\n",
    "            if int(k.real[0])==1:\n",
    "                if int(k.home_money[0])<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.home_money[0]\n",
    "            else:\n",
    "                if k.home_money[0]<0:\n",
    "                    risk=k.home_money[0]\n",
    "                    reward=k.home_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        else:\n",
    "            if int(k.real[0])==0:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=100\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=k.away_money[0]\n",
    "            else:\n",
    "                if k.away_money[0]<0:\n",
    "                    risk=k.away_money[0]\n",
    "                    reward=k.away_money[0]\n",
    "                else:\n",
    "                    risk=-100\n",
    "                    reward=-100\n",
    "        total_risk.append(risk)\n",
    "        total_reward.append(reward)\n",
    "        equal_bet_winnings=reward/-risk*100\n",
    "        equal_bet_return.append(equal_bet_winnings)\n",
    "    natural_ror=round(-np.mean(total_reward)/np.mean(total_risk)*100,2)\n",
    "    equal_bet_ror=round(np.mean(equal_bet_return),2)\n",
    "    return natural_ror,equal_bet_ror\n",
    "# This is a function for creating train-test splits that will work with my way of\n",
    "# scoring model performance based on real world return on risk\n",
    "def test_split(data,test_size,random_state):\n",
    "    shuf_df=data.sample(frac=1,random_state=random_state)\n",
    "    shuf_df.reset_index(drop=True,inplace=True)\n",
    "    df2=shuf_df.copy()\n",
    "    # This seperates the dataframe into data and target \n",
    "    X_temp=df2[df2.columns[1:]]\n",
    "    y=df2.home_win\n",
    "    # This standardized the data\n",
    "    scaler=StandardScaler()\n",
    "    X_s = scaler.fit_transform(X_temp)\n",
    "    X=pd.DataFrame(X_s)\n",
    "    # This does the train-test split in a way that I can carry through the odds values in order to calculate\n",
    "    # the real-world usefulness of the model\n",
    "    if len(X)==len(y):\n",
    "        split_value=int(round(len(X)*(1-test_size),0))\n",
    "        X_train=X.iloc[0:split_value]\n",
    "        X_test=X.iloc[split_value:len(X)]\n",
    "        y_train=y.iloc[0:split_value]\n",
    "        y_test=y.iloc[split_value:len(X)]\n",
    "        home_money=shuf_df.iloc[:,-2]\n",
    "        away_money=shuf_df.iloc[:,-1]\n",
    "    return X_train,X_test,y_train,y_test,home_money,away_money,split_value\n",
    "# This function visualizes the results of a model combination\n",
    "def plot_results(results):\n",
    "    nat_plmean=np.mean(results.nat)\n",
    "    nat_plu=nat_plmean+np.std(results.nat)\n",
    "    nat_pll=nat_plmean-np.std(results.nat)\n",
    "    eq_plmean=np.mean(results.equal)\n",
    "    eq_plu=eq_plmean+np.std(results.equal)\n",
    "    eq_pll=eq_plmean-np.std(results.equal)\n",
    "    scmean=np.mean(results.combo_acc)\n",
    "    scu=scmean+np.std(results.combo_acc)\n",
    "    scl=scmean-np.std(results.combo_acc)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(results.fold,results.nat,label=\"Natural Wagers Return on Risk: {0}%\".format(round(results.nat.mean(),2)))\n",
    "    plt.plot(results.fold,results.equal,label=\"Equal Wagers Return on Risk: {0}%\".format(round(results.equal.mean(),2)))\n",
    "    plt.plot(results.fold,results.vegas_nat,label=\"Vegas Natural Wagers Return on Risk: {0}%\".format(round(results.vegas_nat.mean(),2)))\n",
    "    plt.plot(results.fold,results.vegas_equal,label=\"Vegas Equal Wagers Return on Risk: {0}%\".format(round(results.vegas_equal.mean(),2)))\n",
    "    plt.legend()\n",
    "    plt.title('Real World Return on Risk')\n",
    "    plt.xlabel('Trial Number')\n",
    "    plt.ylabel('Percent Return')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(results.fold,results.combo_acc,label=\"Combined Accuracy Score: {0}\".format(round(results.combo_acc.mean(),2)))\n",
    "    plt.plot(results.fold,results.vegas_acc,label=\"Vegas Accuracy Score: {0}\".format(round(results.vegas_acc.mean(),2)))\n",
    "    if any(\"boost\" in s for s in list(results.columns.values)):\n",
    "        plt.plot(results.fold,results.boost_acc,alpha=.5,label=\"Boost Accuracy Score: {0}\".format(round(results.boost_acc.mean(),2)))\n",
    "    else:\n",
    "        None\n",
    "    if any(\"svm\" in s for s in list(results.columns.values)):\n",
    "        plt.plot(results.fold,results.svm_acc,alpha=.5,label=\"SVM Accuracy Score: {0}\".format(round(results.svm_acc.mean(),2)))\n",
    "    else:\n",
    "        None\n",
    "    if any(\"forest\" in s for s in list(results.columns.values)):\n",
    "        plt.plot(results.fold,results.forest_acc,alpha=.5,label=\"Random Forest Accuracy Score: {0}\".format(round(results.forest_acc.mean(),2)))\n",
    "    else:\n",
    "        None\n",
    "    plt.legend() \n",
    "    plt.title('Visualization of Accuracy Scores')\n",
    "    plt.xlabel('Trial Number')\n",
    "    plt.ylabel('Accuracy Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest and the Support Vector Machine combo:\n",
    "The models vote on the winner and only make predictions when they both agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Random Forest Accuracy Score:  57.03\n",
      "Average SVM Accuracy Score:  55.99\n",
      "Average Combined Accuracy Score:  60.36\n",
      "Average Natural Wager Return on Risk:  4.2\n",
      "Average Equal Wager Return on Risk:  4.76\n"
     ]
    }
   ],
   "source": [
    "results_rf_svm=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    forest=RandomForestClassifier(n_estimators=20,criterion='gini',max_depth=10,\n",
    "                                                 min_samples_split=10,random_state=j*3)\n",
    "    forest.fit(X_train,y_train)\n",
    "    forest_pred=forest.predict(X_test)\n",
    "    svm_clf=svm.SVC(kernel='linear',C=6,random_state=j*3)\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    svm_pred=svm_clf.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if forest_pred[i]+svm_pred[i]==2:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if forest_pred[i]+svm_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    forest_acc=round(accuracy_score(y_test,forest_pred)*100,1)\n",
    "    svm_acc=round(accuracy_score(y_test,svm_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_rf_svm=results_rf_svm.append(pd.DataFrame({'fold':j+1,'forest_acc':forest_acc,\n",
    "                                                       'svm_acc':svm_acc,'combo_acc':combo_acc,\n",
    "                                                       'nat':nat,'equal':equal},index=[0]),ignore_index=True)\n",
    "print('Average Random Forest Accuracy Score: ',round(results_rf_svm.forest_acc.mean(),2))\n",
    "print('Average SVM Accuracy Score: ',round(results_rf_svm.svm_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_rf_svm.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_rf_svm.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_rf_svm.equal.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, combining both predictions results in an improvement in the accuracy score. \n",
    "\n",
    "## Random Forest and the XG Boost combo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Random Forest Accuracy Score:  57.03\n",
      "Average XG Boost Accuracy Score:  61.26\n",
      "Average Combined Accuracy Score:  61.78\n",
      "Average Natural Wager Return on Risk:  2.95\n",
      "Average Equal Wager Return on Risk:  3.35\n"
     ]
    }
   ],
   "source": [
    "results_rf_xg=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    forest=RandomForestClassifier(n_estimators=20,criterion='gini',max_depth=10,\n",
    "                                                 min_samples_split=10,random_state=j*3)\n",
    "    forest.fit(X_train,y_train)\n",
    "    forest_pred=forest.predict(X_test)\n",
    "    boost=xgb.XGBClassifier(learning_rate=.001,max_depth=20,\n",
    "                            min_child_weight=10,n_estimators=200,subsample=.4,gamma=10,random_state=j*3)\n",
    "    boost.fit(X_train,y_train)\n",
    "    boost_pred=boost.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if forest_pred[i]+boost_pred[i]==2:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if forest_pred[i]+boost_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    forest_acc=round(accuracy_score(y_test,forest_pred)*100,1)\n",
    "    boost_acc=round(accuracy_score(y_test,boost_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_rf_xg=results_rf_xg.append(pd.DataFrame({'fold':j+1,'forest_acc':forest_acc,\n",
    "                                                       'boost_acc':boost_acc,'combo_acc':combo_acc,\n",
    "                                                       'nat':nat,'equal':equal,},index=[0]),ignore_index=True)\n",
    "print('Average Random Forest Accuracy Score: ',round(results_rf_xg.forest_acc.mean(),2))\n",
    "print('Average XG Boost Accuracy Score: ',round(results_rf_xg.boost_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_rf_xg.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_rf_xg.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_rf_xg.equal.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see that combining the models impoved the accuracy score, although this time only very slightly. \n",
    "##  SVM and XG Boost combo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SVM Accuracy Score:  55.99\n",
      "Average XG Boost Accuracy Score:  61.26\n",
      "Average Combined Accuracy Score:  63.65\n",
      "Average Natural Wager Return on Risk:  6.24\n",
      "Average Equal Wager Return on Risk:  6.88\n"
     ]
    }
   ],
   "source": [
    "results_svm_xg=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    svm_clf=svm.SVC(C=6,kernel='linear',random_state=j*3)\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    svm_pred=svm_clf.predict(X_test)\n",
    "    boost=xgb.XGBClassifier(learning_rate=.001,max_depth=50,\n",
    "                            min_child_weight=10,n_estimators=200,subsample=.4,gamma=10,random_state=j*3)\n",
    "    boost.fit(X_train,y_train)\n",
    "    boost_pred=boost.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if svm_pred[i]+boost_pred[i]==2:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if svm_pred[i]+boost_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    svm_acc=round(accuracy_score(y_test,svm_pred)*100,1)\n",
    "    boost_acc=round(accuracy_score(y_test,boost_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_svm_xg=results_svm_xg.append(pd.DataFrame({'fold':j+1,'svm_acc':svm_acc,\n",
    "                                                       'boost_acc':boost_acc,'combo_acc':combo_acc,\n",
    "                                                       'nat':nat,'equal':equal},index=[0]),ignore_index=True)\n",
    "print('Average SVM Accuracy Score: ',round(results_svm_xg.svm_acc.mean(),2))\n",
    "print('Average XG Boost Accuracy Score: ',round(results_svm_xg.boost_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_svm_xg.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_svm_xg.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_svm_xg.equal.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we see that combining the models improves the accuracy score. \n",
    "\n",
    "## All three model combo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Random Forerst Accuracy Score:  57.03\n",
      "Average SVM Accuracy Score:  55.99\n",
      "Average XG Boost Accuracy Score:  61.26\n",
      "Average Combined Accuracy Score:  63.77\n",
      "Average Natural Wager Return on Risk:  5.13\n",
      "Average Equal Wager Return on Risk:  6.21\n"
     ]
    }
   ],
   "source": [
    "results_all3=pd.DataFrame([])\n",
    "for j in range(0,50):\n",
    "    X_train,X_test,y_train,y_test,home_money,away_money,split_value=test_split(df,.1,j*3)\n",
    "    forest=RandomForestClassifier(n_estimators=20,criterion='gini',max_depth=10,\n",
    "                                                 min_samples_split=10,random_state=j*3)\n",
    "    forest.fit(X_train,y_train)\n",
    "    forest_pred=forest.predict(X_test)\n",
    "    svm_clf=svm.SVC(C=6,kernel='linear',random_state=j*3)\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    svm_pred=svm_clf.predict(X_test)\n",
    "    boost=xgb.XGBClassifier(learning_rate=.001,max_depth=50,\n",
    "                            min_child_weight=10,n_estimators=200,subsample=.4,gamma=10,random_state=j*3)\n",
    "    boost.fit(X_train,y_train)\n",
    "    boost_pred=boost.predict(X_test)\n",
    "    bets=pd.DataFrame([])\n",
    "    for i in range(len(y_test)):\n",
    "        if svm_pred[i]+boost_pred[i]+forest_pred[i]==3:\n",
    "            bets=bets.append(pd.DataFrame({'preds':1,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "        else:\n",
    "            None\n",
    "        if svm_pred[i]+boost_pred[i]+forest_pred[i]==0:\n",
    "            bets=bets.append(pd.DataFrame({'preds':0,'real':y_test[i+split_value],'home_money':home_money[i+split_value],\n",
    "                                     'away_money':away_money[i+split_value]},index=[0]),ignore_index=True)\n",
    "    forest_acc=round(accuracy_score(y_test,forest_pred)*100,1)\n",
    "    svm_acc=round(accuracy_score(y_test,svm_pred)*100,1)\n",
    "    boost_acc=round(accuracy_score(y_test,boost_pred)*100,1)\n",
    "    combo_acc=round(accuracy_score(bets.real,bets.preds)*100,1)\n",
    "    nat,equal=calc_return(bets)\n",
    "    results_all3=results_all3.append(pd.DataFrame({'fold':j+1,'svm_acc':svm_acc,'boost_acc':boost_acc,\n",
    "                                         'forest_acc':forest_acc,'combo_acc':combo_acc,\n",
    "                                         'nat':nat,'equal':equal},index=[0]),ignore_index=True)\n",
    "print('Average Random Forerst Accuracy Score: ',round(results_all3.forest_acc.mean(),2))\n",
    "print('Average SVM Accuracy Score: ',round(results_all3.svm_acc.mean(),2))\n",
    "print('Average XG Boost Accuracy Score: ',round(results_all3.boost_acc.mean(),2))\n",
    "print('Average Combined Accuracy Score: ',round(results_all3.combo_acc.mean(),2))\n",
    "print('Average Natural Wager Return on Risk: ',round(results_all3.nat.mean(),2))\n",
    "print('Average Equal Wager Return on Risk: ',round(results_all3.equal.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in all three previous examples, combining the models led to an improvement over each individual model.  Below is a table comparing the performances of all of the combinations:\n",
    "\n",
    "|Model|Accuracy|Natural Return on Risk|Equal Wager Return on Risk|\n",
    "|----|----|----|----|\n",
    "|Vegas Odds|61.1%|2.53%|3.11%|\n",
    "|Random Forest + Support Vector Machines|60.36%|4.2%|4.76%|\n",
    "|Random Forest + XG Boost|61.78%|2.95%|3.35%|\n",
    "|Support Vector Machines + XG Boost|63.65%|6.24%|6.88%|\n",
    "|All Three|63.77%|5.13%|6.21%|\n",
    "\n",
    "In light of these results, I am choosing the combination of Support Vector Machines and XG Boost as my final model.  In the next section, I will dive into evaluating how good of a predictor this model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the next section please see the notebook titled \"Evaluting_Final_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
